{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 9\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from alive_progress import alive_bar\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import h5py\n",
    "import mne\n",
    "import sys\n",
    "import os\n",
    "# 输入的是\n",
    "subject_num = 34\n",
    "behaviorVar_exp4_loc = 'E:/workspace/Trust_Data_and_Results/Haoming/varibility/behavior_result/EXP4.txt'\n",
    "result_loc = 'E:/workspace/Trust_Data_and_Results/Haoming/varibility/behavior_result/'\n",
    "eegVar_loc = 'E:/workspace/Trust_Data_and_Results/Haoming/varibility/result/varibilit_corr_20/all_var_data_one_all_6band.npy'\n",
    "var_loc = 'E:/workspace/Trust_Data_and_Results/Haoming/varibility/result/varibilit_corr_20/'\n",
    "\n",
    "behaviorVar_exp4_all_data = []\n",
    "\n",
    "experiment_4_event = [30, 31, 32, 33]\n",
    "\n",
    "event_name_exp2 = ['0Trust', '1Trust', '2Trust', '3Trust']\n",
    "\n",
    "# 时间窗的长度， 单位\n",
    "window_length = 50\n",
    "\n",
    "# 需要分析的数据起止时间 第一位是开始的时间，第二位是结束的时间\n",
    "involve_time = [-0.1, 0.7]\n",
    "# 34 1 1 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从text中提取数据\n",
    "all_subject_list = pd.read_csv(behaviorVar_exp4_loc, delimiter='\\t')#, names=['Subject', 'Age'\t,'Sex',\t'face1.ACC', 'face1.RESP', 'face1.RT', 'or'/'type'])\n",
    "\n",
    "# 所有被试的编号\n",
    "#all_subject_number = np.sort(np.unique(all_subject_list[all_subject_list.keys()[0]]))\n",
    "\n",
    "# 减去空集 NAN\n",
    "all_subject_list = all_subject_list.dropna()\n",
    "\n",
    "all_subject_number = np.sort(np.unique(all_subject_list[all_subject_list.keys()[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有被试的平均数据放在以\n",
    "all_subject, all_subject_trialnum = [], []\n",
    "event_value = {}\n",
    "\n",
    "for iter_subject in range(len(all_subject_number)):\n",
    "\n",
    "    # 先获得每一个被试的数据位置（行数）\n",
    "    iter_subject_position = np.where(all_subject_list[all_subject_list.keys()[0]] == all_subject_number[iter_subject])\n",
    "\n",
    "    # total_len.append(len(iter_subject_position[0]))\n",
    "    iter_subject_list = all_subject_list.iloc[iter_subject_position]\n",
    "    \n",
    "    # 提取四种条件，其平均数 以及该条件的个数\n",
    "    iter_subject, ter_subiject_trialnum = [], []\n",
    "    \n",
    "    # 对每一个event进行一次循环（目前共四个）\n",
    "    for iter_event in experiment_4_event:\n",
    "        # 检查每一个event在该被试中对应的位置\n",
    "        iter_event_position = np.where(iter_subject_list[iter_subject_list.keys()[-1]] == iter_event)\n",
    "        # 统计每个event的数量\n",
    "        event_num = len(iter_event_position[0])\n",
    "        # 截取出该event的dataframe\n",
    "        iter_event_list = iter_subject_list.iloc[iter_event_position]\n",
    "        # 截取数据段\n",
    "        iter_event_value = np.array(iter_event_list[iter_event_list.keys()[5]])\n",
    "        # 求平均数\n",
    "        # iter_event_value = np.mean(iter_event_list[iter_event_list.keys()[3]])\n",
    "        # 存到数组的第一个维度\n",
    "        iter_subject.append(iter_event_value)\n",
    "        # ter_subiject_trialnum.append(event_num)\n",
    "    #event_value = pd.DataFrame(event_value)\n",
    "    # 存到总数组的第二个维度\n",
    "    all_subject.append(iter_subject)\n",
    "    # all_subject_trialnum.append(ter_subiject_trialnum)\n",
    "\n",
    "\n",
    "# 储存该np数组\n",
    "all_subject = np.array(all_subject)\n",
    "all_subject = all_subject - 1 \n",
    "# all_subject_trialnum = np.array(all_subject_trialnum)\n",
    "\n",
    "if not os.path.exists(result_loc):\n",
    "    os.makedirs(result_loc)\n",
    "\n",
    "np.save(result_loc + 'all_subject_exp4.npy', all_subject)\n",
    "# np.save(result_loc + 'all_subject_trialnum.npy', all_subject_trialnum)\n",
    "#print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_subject_exp4 = np.load(result_loc + 'all_subject_exp4.npy')\n",
    "all_subject_exp4_condition01 = np.mean(all_subject_exp4[:,0:2,:], axis = 1)\n",
    "all_subject_exp4_condition23 = np.mean(all_subject_exp4[:,2:4,:], axis = 1)\n",
    "all_subject_exp4_condition01 = np.mean(all_subject_exp4_condition01, axis = 1)\n",
    "all_subject_exp4_condition23 = np.mean(all_subject_exp4_condition23, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mean_deference = all_subject_exp4_condition23 - all_subject_exp4_condition01\n",
    "behavior_varibility = exp_mean_deference\n",
    "\n",
    "eeg_varibility = np.load(var_loc + 'all_var_data_nor.npy', allow_pickle=True).item()\n",
    "print(behavior_varibility.shape)\n",
    "print(eeg_varibility.keys())\n",
    "\n",
    "print(eeg_varibility['data'].shape)\n",
    "print(eeg_varibility['event_name'])\n",
    "# print(behavior_varibility)\n",
    "\n",
    "# Subjects with incomplete data were removed\n",
    "bad_subject = np.array([3, 5, 15]) -1\n",
    "all_subject = np.arange(0,34,1)\n",
    "\n",
    "# Delete specific elements\n",
    "good_subject = np.setdiff1d(all_subject, bad_subject)\n",
    "\n",
    "\n",
    "eeg_varibility['data'] = eeg_varibility['data'][good_subject]\n",
    "behavior_varibility = behavior_varibility[good_subject]\n",
    "print(eeg_varibility['data'].shape)\n",
    "print(behavior_varibility.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_location_dict = {\"Fp1\":\t[-26.25, 83, -18.25],\n",
    "\"Fp2\": [26.25, 83, -18.25],\n",
    "\"F3\": [-48.75, 57.5, 36.5],\n",
    "\"F4\": [48.75, 57.5, 36.5],\n",
    "\"C3\": [-63.75, -13, 65.75],\n",
    "\"C4\": [63.75, -13, 65.75],\n",
    "\"P3\": [-48, -86.5, 53],\n",
    "\"P4\": [48, -86.5, 53],\n",
    "\"O1\": [-27, -118, 4.25],\n",
    "\"O2\": [27, -118, 4.25],\n",
    "\"F7\": [-69, 44, -18.25],\n",
    "\"F8\": [69, 44, -18.25],\n",
    "\"T7\": [-84, -18.25, -13],\n",
    "\"T8\": [84, -18.25, -13],\n",
    "\"P7\": [-69, -80.5, -4.75],\n",
    "\"P8\": [69, -80.5, -4.75],\n",
    "\"Fz\": [0, 63.5, 59],\n",
    "\"Cz\": [0, -10, 99.5],\n",
    "\"Pz\": [0, -88, 77],\n",
    "\"FC1\": [-32.25, 28.25, 77.75],\n",
    "\"FC2\": [32.25, 28.25, 77.75],\n",
    "\"CP1\": [-35.25, -52, 90.5],\n",
    "\"CP2\": [35.25, -52, 90.5],\n",
    "\"FC5\": [-75.75, 20, 21.5],\n",
    "\"FC6\": [75.75, 20, 21.5],\n",
    "\"CP5\": [-78, -51.25, 31.25],\n",
    "\"CP6\": [78, -51.25, 31.25],\n",
    "\"FT9\": [-72.75, 8.75, -55.75],\n",
    "\"FT10\": [72.75, 8.75, -55.75],\n",
    "\"TP9\": [-71.25, -49, -49.75],\n",
    "\"TP10\": [71.25, -49, -49.75],\n",
    "\"F1\": [-25.5, 62, 53.75],\n",
    "\"F2\": [25.5, 62, 53.75],\n",
    "\"C1\": [-35.25, -11.5, 89.75],\n",
    "\"C2\": [35.25, -11.5, 89.75],\n",
    "\"P1\": [-27, -88, 70.25],\n",
    "\"P2\": [27, -88, 70.25],\n",
    "\"AF3\": [-32.25, 80.75, 11.75],\n",
    "\"AF4\": [32.25, 80.75, 11.75],\n",
    "\"FC3\": [-59.25, 25.25, 54.5],\n",
    "\"FC4\": [59.25, 25.25, 54.5],\n",
    "\"CP3\": [-63, -52, 66.5],\n",
    "\"CP4\": [63, -52, 66.5],\n",
    "\"PO3\": [-31.5, -109.75, 32.75],\n",
    "\"PO4\": [31.5, -109.75, 32.75],\n",
    "\"F5\": [-63, 51.5, 11.75],\n",
    "\"F6\": [63, 51.5, 11.75],\n",
    "\"C5\": [-81.75, -14.5, 29],\n",
    "\"C6\": [81.75, -14.5, 29],\n",
    "\"P5\": [-63.75, -83.5, 26.75],\n",
    "\"P6\": [63.75, -83.5, 26.75],\n",
    "\"AF7\": [-50.25, 68, -19],\n",
    "\"AF8\": [50.25, 68, -19],\n",
    "\"FT7\": [-79.5, 15.5, -16],\n",
    "\"FT8\": [79.5, 15.5, -16],\n",
    "\"TP7\": [-80.25, -49.75, -8.5],\n",
    "\"TP8\": [80.25, -49.75, -8.5],\n",
    "\"PO7\": [-50.25, -103, 0.5],\n",
    "\"PO8\": [50.25, -103, 0.5],\n",
    "\"Fpz\": [0, 83, -18.25],\n",
    "\"CPz\": [0, -53.5, 98],\n",
    "\"POz\": [0, -109, 44],\n",
    "\"Oz\": [0, -122.5, 8]}\n",
    "# ['Fp1', 'Fp2', 'Fz', 'Cz', 'Pz', 'Fpz', 'CPz', 'POz', 'Oz'].\n",
    "mymontage = mne.channels.make_dig_montage(ch_pos=channel_location_dict)#, nasion=[0, -10, 99.5], lpa=[-71.25, -49, -49.75], \n",
    "#                                        rpa=[71.25, -49, -49.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "power_name = ['alpha']\n",
    "\n",
    "\n",
    "time_series = np.arange(-0.2, 1, 0.001)\n",
    "time_series = np.around(time_series,3)\n",
    "start_time = np.where(time_series == involve_time[0])[0][0]\n",
    "end_time = np.where(time_series == involve_time[1])[0][0]\n",
    "\n",
    "iter_power = 2\n",
    "figure_result_loc = 'E:/workspace/Trust_Data_and_Results/Haoming/varibility/result/varibilit_corr_20/corr_result/temporal_figure/exp1eeg_exp4beha_spearman'\n",
    "\n",
    "iter_condition_and_power_result = []\n",
    "for iter_elec in tqdm(range(eeg_varibility['data'].shape[-2])):\n",
    "    \n",
    "    iter_elec_result = []\n",
    "    \n",
    "    for iter_window in range(end_time - start_time):# 步长为1\n",
    "        \n",
    "        t_begin = start_time + iter_window - round(window_length/2)\n",
    "        t_end = start_time + iter_window + round(window_length/2)\n",
    "\n",
    "        iter_eeg_varibility_data = eeg_varibility['data'][:,iter_power+1, 0, iter_elec, t_begin:t_end]\n",
    "        iter_eeg_varibility_data_mean = np.mean(iter_eeg_varibility_data, axis=-1)\n",
    "\n",
    "        \n",
    "        x = behavior_varibility\n",
    "        y = iter_eeg_varibility_data_mean\n",
    "\n",
    "        \n",
    "        scipy_corr = scipy.stats.pearsonr(x, y)\n",
    "        \n",
    "\n",
    "        if (scipy_corr[1] <= 0.05) & (scipy_corr[0] > 0):\n",
    "            iter_elec_result.append(1)\n",
    "        elif (scipy_corr[1] <= 0.05) & (scipy_corr[0] < 0):\n",
    "            iter_elec_result.append(-1)\n",
    "        else:\n",
    "            iter_elec_result.append(0)\n",
    "\n",
    "    \n",
    "    iter_condition_and_power_result.append(iter_elec_result)\n",
    "\n",
    "iter_condition_and_power_result= np.array(iter_condition_and_power_result)\n",
    "# create a new epochs info\n",
    "info = mne.create_info(\n",
    "    ch_names = eeg_varibility['ch_names'],\n",
    "    ch_types = 'eeg',\n",
    "    sfreq = 1000)\n",
    "\n",
    "# create a new ROI based epochs\n",
    "significiant_evoked = mne.EvokedArray(data = iter_condition_and_power_result, \n",
    "    info = info, tmin=-0.1)\n",
    "\n",
    "significiant_evoked.set_montage(mymontage)\n",
    "# plt.close('all')\n",
    "#plt.rcParams['figure.figsize'] = (20,20)\n",
    "all_time = np.arange(-0.1, 0.35, 0.002)\n",
    "all_time = np.around(all_time, 3)\n",
    "for iter_times in range(len(all_time)):\n",
    "\n",
    "    times = all_time[iter_times]\n",
    "    fig = significiant_evoked.plot_topomap(outlines='head',times=times, size=5, vmin=-1500000, vmax=1500000, show_names=False, sensors='kv', extrapolate='head', cmap='RdBu_r', scalings=None, colorbar=False)# cmap GnBu\n",
    "\n",
    "\n",
    "    iter_figure_result_loc = figure_result_loc + '/' + power_name[iter_power] + '/'\n",
    "    if not os.path.exists(iter_figure_result_loc):\n",
    "        os.makedirs(iter_figure_result_loc)\n",
    "\n",
    "    fig.savefig(iter_figure_result_loc + str(iter_times) + '_' + str(times) + '_pic.png')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
